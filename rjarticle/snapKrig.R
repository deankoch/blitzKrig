# Generated by `rjournal_pdf_article()` using `knitr::purl()`: do not edit by hand
# Please edit snapKrig.Rmd to modify this file

## ----setup, include=FALSE-----------------------------------------------------
knitr::opts_chunk[['set']](echo = FALSE, warning = FALSE, message = FALSE)
# Try adding \usepackage{float} with chunk option fig.pos='h' if floating figures are driving you crazy.

# spatial libraries
library(sp)
library(sf)
library(terra)
library(snapKrig)

# directory management
library(here)

# define paths to test result files
dir_project = here('rjarticle')
dir_storage = file.path(dir_project, 'data')
path_cv_result = file.path(dir_storage, 'cv_results.csv')
path_bench_result = file.path(dir_storage, 'bench_results.csv')
path_dem = file.path(dir_storage, 'treed_dem.tif')
path_treed = file.path(dir_storage, 'treed.tif')

# load helpers and prepared datasets
source(file.path(dir_storage, 'data_helpers.R'))
meuse_list = get_meuse(dfMaxLength=NA)

# copy the log zinc points data
pts = meuse_list[['soils']]['log_zinc']

# save default graphical parameters
.par_default = par(no.readonly=TRUE)

# set up a common color palette (this is the default in snapKrig)
.pal = function(n) { hcl.colors(n, 'Spectral', rev=TRUE) }

library(smoothr)
library(ggplot2)



## ----cfun-prep----------------------------------------------------------------
# define column names and a caption for the (two) calls below that make the table for the html and latex outputs
cfun_colnames = c('code', 'name', 'alias', '$c\\left( \\Delta \\right)$')
cfun_caption = 'A list of one-dimensional correlation functions available in snapKrig. Kronecker covariances are constructed from the product of a pair of these functions, one receiving the $x$ separation distance as its argument, and the other the $y$ distance. Normalization constants are omitted for brevity, and $K_p$ denotes the order-$p$ Bessel function of the second kind (where $p$ is a shape parameter).'

# define the table
cfun_df = data.frame(

  code = c('exp', 'gau', 'gex',  'mat', 'sph'),
  name = c('Exponential', 'Gaussian', 'Gamma-Exponential', "Mat\\'ern", 'Spherical'),
  alias = c('-', 'Squared-Exponential, or Stable Kernel', 'Power-Exponential', "Whittle-Mat\\'ern", '-'),
  fun = c('$\\exp\\left( -\\Delta \\right)$',
          '$\\exp\\left( -\\Delta^2 \\right)$',
          '$\\exp\\left( -\\Delta^p \\right)$',
          '$\\Delta^p K_p\\left( \\Delta \\right)$',
          '$1 - (3/2)\\Delta + (1/2)\\Delta^3$')
)


## ----cfun-table, eval = knitr::is_html_output()-------------------------------
#> knitr::kable(cfun_df, format='html', col.names=cfun_colnames, caption=cfun_caption, escape=FALSE)


## ----cfun-table-latex, eval = knitr::is_latex_output()------------------------
kableExtra::kable_styling(knitr::kable(cfun_df, format='latex', col.names=cfun_colnames, booktabs=TRUE, escape=FALSE, caption=cfun_caption), font_size=9)


## ----meuse-setup, include=TRUE, echo=TRUE-------------------------------------
# snap log zinc data to grid of specified resolution
g = sk_snap(pts, g=list(gres=c(y=50, x=50)))
summary(g)


## ----meuse-png, echo=FALSE, results='hide', fig.show='hold', out.width='50%', fig.dim=c(5,5), fig.cap='Zinc concentrations (in log parts per billion) from the Meuse dataset, a soil survey on the floodplain of the Meuse River (left). These data are snapped to a grid for use with snapKrig (right)', fig.alt='Two panes show two versions of the same soils data. The left pane shows a diagram of the winding Meuse river surrounded by about a hundred colored points. The points are coloured according to zinc levels at sample sites, and all are located in the vicinity of the river floodplain. In the right pane, a black-and-white grid of intersecting lines covers the same area. This grid is mostly empty (white), but a small number of cells are coloured - one for each point on the left pane.'----

# snap points to 50m x 50m grid
g = sk_snap(pts, g=list(gres=c(y=50, x=50)))

# plot source data using sf package, restoring default graphical parameters afterwards
plot(pts, pch=16, reset=FALSE, pal=.pal, key.pos=1, main='Meuse data', cex.main=0.8)
plot(st_geometry(pts), pch=1, add=TRUE)
plot(meuse_list[['river_poly']], col='lightblue', border=NA, add=TRUE)
plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)

# plot gridded version using the snapKrig package
plot(g, col_grid='lightgrey', reset=FALSE, zlab='log(ppb)', main='snapped at 50m resolution')
plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)


## ----meuse-ok, include=TRUE, echo=TRUE----------------------------------------
# fit the covariance model and mean
fit_result_ok = sk_fit(g, quiet=TRUE)


## ----meuse-ok-pred, echo=TRUE-------------------------------------------------
# compute conditional mean and variance 
g_ok = sk_cmean(g, pars=fit_result_ok)
g_ok_var = sk_cmean(g, pars=fit_result_ok, what='v', quiet=TRUE)


## ----meuse-ok-pred-png, results='hide', fig.show='hold', out.width='50%', fig.dim=c(5,5), fig.cap='Ordinary kriging prediction and variance heatmaps generated by snapKrig for the Meuse example. Predictions are generated for the entire grid, but they are masked in this plot to show detail in areas nearest the observed points.', fig.alt='Two heatmap images are shown, both masked to the same region as the previous figure. These heatmaps cover the convex hull of the observed zinc sample points, and within this region they show a range of smoothly varying colors.'----
# make a mask for high variance locations
is_var_high = g_ok_var[] > quantile(g_ok_var, 0.4, na.rm=TRUE)

# set masked pixels to NA on plot
g_ok_plot = g_ok 
g_ok_plot[is_var_high] = NA
g_ok_var_plot = g_ok_var
g_ok_var_plot[is_var_high] = NA

# plot predictor on log scale with river line 
sk_plot(g_ok_plot, axes=FALSE,
        zlab = 'log(ppb)',
        xlab = '',
        ylab = '',
        main = 'ordinary kriging predictor',
        col_box = 'grey',
        reset = FALSE,
        cex.main = 1.1)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)

# plot variance  
sk_plot(g_ok_var_plot, axes=FALSE,
        zlab = 'V(x,y)',
        xlab = '',
        ylab = '',
        main = 'ordinary kriging variance',
        col_box = 'grey',
        pal = 'Inferno',
        reset = FALSE,
        cex.main = 1.1)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)


## ----meuse-uk-prep, echo=TRUE-------------------------------------------------
# measure distances for every point in the grid
river_dist = sf::st_distance(sk_coords(g, out='sf'), meuse_list[['river_line']])
river_dist = units::drop_units(river_dist)

# include distance covariate (and optionally its square root)
X = g
X[] = scale(river_dist)
#X[] = scale(cbind(river_dist, sqrt(river_dist)))
summary(X)


## ----meuse-uk, echo=TRUE------------------------------------------------------
# fit the covariance model again with X
fit_result_uk = sk_fit(g, X=X, quiet=TRUE)

# compute conditional mean and variance
g_uk = sk_cmean(g, fit_result_uk, X)
g_uk_var = sk_cmean(g, fit_result_uk, X, what='v', quiet=TRUE)


## ----meuse-lm, echo=TRUE------------------------------------------------------
# use GLS to estimate the spatially varying trend 
g_lm = sk_GLS(g, fit_result_uk, X=X)


## ----meuse-uk-pred-png, results='hide', fig.show='hold', out.width='33%', fig.dim=c(6,8), fig.cap='Universal kriging predictions and variance generated by snapKrig for the Meuse example. The response variable (log zinc concentration) is de-trended using a linear predictor (left) based on distance to river, resulting in more detail in kriging predictions (middle) and variance (right)', fig.alt='Three heatmap images are shown, all masked to the same region as the previous two figures (centered over the winding Meuse River). In the left pane, colours becoming brighter near the river; In middle pane, colors vary smoothly to roughly match the colours of the point data in the previous figure. In the right pane, colors vary smoothly in a way that matches the density of the points in the previous figure.'----

# mask same pixels as previous plot
g_lm_plot = g_lm
g_uk_plot = g_uk
g_uk_var_plot = g_uk_var
g_lm_plot[is_var_high] = NA
g_uk_plot[is_var_high] = NA
g_uk_var_plot[is_var_high] = NA

# plot linear predictor on log scale with river line 
sk_plot(g_lm_plot, axes=FALSE,
        zlab = 'log(ppb)',
        xlab = '', ylab = '',
        main = 'covariates',
        col_box = 'grey',
        cex.main = 2.1,
        cex.z = 1.5,
        reset = FALSE)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)

# plot kriging predictor on log scale with river line 
sk_plot(g_uk_plot, axes=FALSE,
        zlab = 'log(ppb)',
        xlab = '', ylab = '',
        main = 'universal kriging predictor',
        col_box = 'grey',
        cex.main = 2.1,
        cex.z = 1.5,
        reset = FALSE)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)

# plot kriging variance on log scale with river line 
sk_plot(g_uk_var_plot, axes=FALSE,
        zlab = 'V(x,y)',
        xlab = '', ylab = '',
        main = 'universal kriging variance',
        col_box = 'grey',
        pal = 'Inferno',
        cex.main = 2.1,
        cex.z = 1.5,
        reset = FALSE)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)



## ----meuse-ok-vg, results='hide'----------------------------------------------
# compute sample semivariogram for the OK model
vg_ok = sk_sample_vg(g)

# recompute variogram with trend removed
vg_UK = sk_sample_vg(g - g_lm)


## ----meuse-vg-png, fig.show='hold', out.width='50%', fig.dim=c(4, 3), fig.pos='!htb', fig.cap='Fitted covariance models from kriging on the Meuse dataset, visualized in two ways: On the left, estimated semi-variogram values (circles) are plotted next to fitted model values (blue curves). On the right, a heatmap displays covariances with respect to the central point. The top two plots show the fitted OK model. The bottom two plots show the UK model, where removing a linear trend from the response data has resulted in higher variance and a smaller range.', fig.alt='A four panel plot arranged in a square: the top-left pane is a scatterplot of points in the shape of a hill, with a smooth blue curve approximately following the pattern of points. The top-right pane shows a heatmap resembling a blurry photo of a ball. The bottom two panes are similar, but the point pattern in the scatterplot (bottom-left) traces out a much shallower hill, and in the blurry heatmap image (bottom-right), the ball is much smaller.'----

# plot the sample semi-variogram with theoretical curve in blue for OK model fit
par(mar=c(5.1, 5.1, 4.1, 2.1))
sk_plot_semi(vg_ok, fit_result_ok,
             main = 'OK model semi-variogram', 
             lwd = 2,
             d_max = 2 * fit_result_ok$y$kp, 
             alpha_bin_b = 0.2, 
             alpha_bin = 0.2,
             alpha_model = 0.3)

box('outer', col='lightgrey')
par(.par_default)

# plot correlation heatmap for OK model fit
g_plot = modifyList(g, list(gdim=rep(min(g[['gdim']]), 2), gyx=NULL, gval=NULL))
sk_plot_pars(fit_result_ok, g_plot, ij=T, main='', col_box = 'grey')

# plot the sample semi-variogram with theoretical curve in blue
par(mar=c(5.1, 5.1, 4.1, 2.1))
sk_plot_semi(vg_UK, fit_result_uk, 
             main = 'UK model semi-variogram', 
             lwd = 2,
             d_max = 2 * fit_result_uk$y$kp, 
             alpha_bin_b = 0.2, 
             alpha_bin = 0.2,
             alpha_model = 0.3)

box('outer', col='lightgrey')
par(.par_default)

# plot correlation heatmap
g_plot = modifyList(g, list(gdim=rep(min(g[['gdim']]), 2), gyx=NULL, gval=NULL))
sk_plot_pars(fit_result_uk, g_plot, ij=T, main='', col_box = 'grey')




## ----meuse-uk-aniso, echo=TRUE------------------------------------------------
# fit Gaussian covariance with geometric anisotropy
fit_result_uk_gau = sk_fit(g, pars='gau', X=X, iso=FALSE, quiet=TRUE)


## ----meuse-uk-aniso2, echo=TRUE-----------------------------------------------
# fit four other covariance functions with anisotropy
fit_result_uk_sph = sk_fit(g, pars='sph', X=X, iso=FALSE, quiet=TRUE)
fit_result_uk_exp = sk_fit(g, pars='exp', X=X, iso=FALSE, quiet=TRUE)
fit_result_uk_mat = sk_fit(g, pars='mat', X=X, iso=FALSE, quiet=TRUE)
fit_result_uk_gxp = sk_fit(g, pars='gxp', X=X, iso=FALSE, quiet=TRUE)


## ----meuse-alt-fit, fig.show='hold', out.width='19%', fig.dim=c(5,5), fig.pos='!htb', fig.cap='Five examples of anisotropic covariance structures fitted to the Meuse data. As in the previous figure, darker pixels indicate stronger correlation with the central point. From left to right, these are the Kronecker covariances formed by setting both $c_x$ and $c_y$ equal to "gau", "mat", "gxp", "sph", and "exp" models, respectively.', fig.alt='A sequence of five heatmap panes are displayed side by side. Each one shows an image resembling a blurry photo of a small object. In the first three panes, this ball is egg-shaped and the heatmaps are nearly identical. In the last two panes (and particularly, in the far right pane), the ball is shaped more like a diamond, with corners oriented up-down and left-right.'----

# compile all fitted parameters
pars_list = list(uk_gau = fit_result_uk_gau,
                 uk_mat = fit_result_uk_mat,
                 uk_gxp = fit_result_uk_gxp,
                 uk_sph = fit_result_uk_sph,
                 uk_exp = fit_result_uk_exp)

# make a list of titles
title_list = c('Gaussian', 'Matérn', 'Gamma-Exponential', 'Spherical', 'Exponential')

# plot everything in minimal style
g_plot = modifyList(g, list(gdim=rep(min(g[['gdim']]), 2), gyx=NULL, gval=NULL))
cex_main_kernels = 2.5
plot_result = Map(\(p, m) {
  
  sk_plot_pars(p, g_plot,
             minimal = TRUE,
             col_box = 'grey',
             main = m,
             cex.main = cex_main_kernels,
             xlab = '', ylab = '',
             pal = 'Inferno')

  }, p=pars_list, m=title_list)

par(.par_default)



## ----meuse-alt-pred, results='hide'-------------------------------------------

# compile all fitted parameters
pars_list = list(uk_gau = fit_result_uk_gau,
                 uk_mat = fit_result_uk_mat,
                 uk_gxp = fit_result_uk_gxp,
                 uk_sph = fit_result_uk_sph,
                 uk_exp = fit_result_uk_exp)
        
# collect all model fitting results into a list
all_results = c(list(ok=fit_result_ok), pars_list)

# check likelihood, AIC and BIC for all models
all_uk = sapply(all_results, \(p) sk_LL(p, g, X, out='m'))

# compute conditional kriging mean and variance for three of the models 
g_uk_mat = sk_cmean(g, fit_result_uk_mat, X)
g_uk_sph = sk_cmean(g, fit_result_uk_sph, X)
g_uk_exp = sk_cmean(g, fit_result_uk_exp, X)
g_uk_mat_var = sk_cmean(g, fit_result_uk_mat, X, what='v')
g_uk_sph_var = sk_cmean(g, fit_result_uk_sph, X, what='v')
g_uk_exp_var = sk_cmean(g, fit_result_uk_exp, X, what='v')

# check fitted vs predicted
# plot(g[!is.na(g)], g_uk_sph[!is.na(g)])
# abline(0,1)
# plot(g[!is.na(g)], g_uk_exp[!is.na(g)])
# abline(0,1)
# plot(g[!is.na(g)], g_uk_mat[!is.na(g)])
# abline(0,1)
# plot(g[!is.na(g)], g_uk[!is.na(g)])
# abline(0,1)
# plot(g[!is.na(g)], g_ok[!is.na(g)])
# abline(0,1)



## ----meuse-alt-pred-png, results='hide', fig.show='hold', out.width='33%', fig.dim=c(5,6), fig.pos='!bht', fig.cap='Universal kriging predictions for the Meuse example using three anisotropic Kronecker covariance models, based on the Gaussian, exponential, and spherical correlograms.', fig.alt='A set of three heatmaps are shown side-by-side.These depicting the same aerial view of the Meuse river floodplain as shown in the the first two figures of this paper. Each pane shows a smoothly varying field of colours roughly matching to the colours of the sample points displayed in Figure 1. The three images are very similar, but the first pane is noticeably smoother than the others'----

# mask same pixels as previous plot
g_uk_gau_plot = g_uk_mat 
g_uk_exp_plot = g_uk_exp 
g_uk_sph_plot = g_uk_sph 
g_uk_gau_plot[is_var_high] = NA
g_uk_exp_plot[is_var_high] = NA
g_uk_sph_plot[is_var_high] = NA

zlim = range(sapply(list(g_uk_gau_plot, g_uk_exp_plot, g_uk_sph_plot), range, na.rm=TRUE))

# plot kriging predictor on log scale with river line 
sk_plot(g_uk_gau_plot, axes=FALSE, zlim=zlim,
        zlab = 'log(ppb)\n',
        xlab = '', ylab = '',
        main = 'Gaussian',
        cex.main = 1.6,
        cex.z = 1.5,
        col_box='grey',
        reset = FALSE)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)

# plot kriging variance on log scale with river line 
sk_plot(g_uk_exp_plot, axes=FALSE, zlim=zlim,
        zlab = 'log(ppb)\n',
        xlab = '', ylab = '',
        main = 'Exponential',
        cex.main = 1.6,
        cex.z = 1.5,
        col_box = 'grey',
        reset = FALSE)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)

# plot kriging variance on log scale with river line 
sk_plot(g_uk_sph_plot, axes=FALSE, zlim=zlim,
        zlab = 'log(ppb)\n',
        xlab = '', ylab = '',
        main = 'Spherical',
        cex.main = 1.6,
        cex.z = 1.5,
        col_box = 'grey',
        reset = FALSE)

plot(meuse_list[['river_line']], col='black', lwd=1, add=TRUE)
par(.par_default)



## ----meuse-cv-prep------------------------------------------------------------

# copy fitted model parameters
anisotropy_pars = list(uk_gau = fit_result_uk_gau,
                          uk_mat = fit_result_uk_mat,
                          uk_gxp = fit_result_uk_gxp,
                          uk_sph = fit_result_uk_sph,
                          uk_exp = fit_result_uk_exp)

# collect all model fitting results into a list
all_pars = c(list(ok=fit_result_ok, uk=fit_result_uk), anisotropy_pars)

# check likelihood, AIC and BIC for all universal kriging models
all_uk_results = data.frame(lapply(all_pars[-1], \(p) unlist(sk_LL(p, g, X, out='m'))))

# combine with results on ok model (omit X from this call)
ok_results = data.frame(ok=unlist(sk_LL(fit_result_ok, g, X=NA, out='m')))

all_results = cbind(ok_results, all_uk_results)
all_IC = data.frame(t(all_results[c('AIC', 'BIC'),])) 

# load pre-computed CV results
cv_results_all = read.csv(path_cv_result, row.names=NULL)

# create a data frame with everything relevant
table_df = cbind(all_IC, cv_results_all[c('isotropic', 'covariates', 'parameters', 'rMSPE', 'rMSPEb')])
table_df[['$c_x$']] = c('gau', 'gau', 'gau', 'mat', 'gxp', 'sph', 'exp')
table_df[['$c_y$']] = table_df[['$c_x$']]
table_df = table_df[c('covariates', 'isotropic', '$c_y$', '$c_x$', 'parameters', 'AIC', 'BIC', 'rMSPE', 'rMSPEb')]
rownames(table_df) = NULL

# formatting
table_df[['covariates']] = c('no', 'yes')[1+as.logical(table_df[['covariates']])]
table_df[['isotropic']] = c('no', 'yes')[1+as.logical(table_df[['isotropic']])]
table_df[['AIC']] = round(table_df[['AIC']], 1)
table_df[['BIC']] = round(table_df[['BIC']], 1)
table_df[['rMSPE']] = round(table_df[['rMSPE']], 3)
table_df[['rMSPEb']] = round(table_df[['rMSPEb']], 2)

# define caption text here
caption_cv = 'Estimates of the root mean squared prediction error on the Meuse dataset for log zinc (rMSPE) and its back-transformed values (rMSPEb) in a 25 X 5-fold cross-validation (CV) experiment. Results are reported for all seven of the kriging models presented in this paper, along with the AIC and BIC scores for models fitted to all observed data.'


## ----cv-table, eval = knitr::is_html_output()---------------------------------
#> knitr::kable(table_df, format='html', caption=caption_cv)


## ----cv-table-latex, eval = knitr::is_latex_output()--------------------------
kableExtra::kable_styling(knitr::kable(table_df, format='latex', booktabs=TRUE, linesep='', caption=caption_cv, escape=FALSE), font_size=9)


## ----treed-png, results='hide', fig.dim=c(4.5,4), fig.show='hold', out.width='33%', fig.pos='htb', fig.cap='A 1021 x 1349 raster on forest density in central BC, Canada (left) was up-scaled to produce a much coarser resolution version with dimensions 32 x 43 (middle). snapKrig is optimized for downscaling rasters like these. Model fitting and prediction of over a million points at original resolution (right), with elevation as a predictor, took less than three seconds.', fig.alt='Three panels are shown side-by-side, each one showing pine forest cover over a common area, as it would appear looking down from an aircraft. The images are dominated by green, corresponding to dense forest, with exceptions like high alpine and river valleys in depicted in white, where no pine grow. The left panel is a high-resolution image of the source data. The middle panel shows the same image at very coarse resolution. The right panel has the same resolution as the left panel, and contains much of the same information, but the image is more blurry.'----

# load the treed raster data and a matching DEM
g_treed = sk(rast(path_treed))
g_dem = sk(rast(path_dem))

# make a training set at much coarser resolution
g_train = sk_rescale(g_treed, up=32)
g_train_dem = sk_rescale(g_dem, up=32)

# snap training points to original grid (NAs everywhere else)
g_out = sk_snap(sk_coords(g_train, out='sf'), g_treed)

# use elevation and (optionally its square root) as covariate
X = g_dem
#X[] = scale(cbind(X[], sqrt(X)[]))
X[] = scale(X[])

# smaller version for training
X_train = g_train_dem
#X_train[] = scale(cbind(X_train[], sqrt(X_train)[]))
X_train[] = scale(X_train[])

# fit the model
start_fit = Sys.time()
  treed_fit_result = sk_fit(g_train, X=X_train, iso=FALSE, pars='gau', quiet=TRUE)
end_fit = Sys.time()

# make predictions
start_pred = Sys.time()
  g_treed_pred = sk_cmean(g_out, X=X, pars=treed_fit_result)
end_pred = Sys.time()

# report both times
print(end_fit-start_fit)
print(end_pred-start_pred)

# find a common range for colorbar
zlim = range(c(g_treed_pred[], g_train[], g_treed[]), na.rm=TRUE)
pal_nm = 'YlGn'
pal = function(n) { hcl.colors(n, pal_nm, rev=TRUE) }

# draw the three plot panes
sk_plot(g_treed, zlim=zlim,
        main = 'treed data (original scale)',
        col_box = 'grey',
        minimal = TRUE,
        pal = pal_nm,
        rev = TRUE,
        cex.main = 1.4,
        col_box = 'black')

sk_plot(g_train, zlim=zlim,
        main = 'treed data (up-scaled)',
        col_box  =  'grey',
        minimal = TRUE,
        col_grid = 'white',
        pal = pal_nm,
        cex.main = 1.4,
        rev = TRUE)

sk_plot(g_treed_pred, zlim=zlim,
        zlab = 'density',
        main = 'kriging predictor', 
        col_box  =  'grey',
        minimal = TRUE,
        pal = pal_nm,
        cex.main = 1.4,
        rev = TRUE)



## ----bench-results------------------------------------------------------------
# load the benchmarking results
results_df = read.csv(path_bench_result, row.names=NULL)
results_names = unique(results_df[['name']])
results_df[['is_complete']] = c('no', 'yes')[1 + as.integer(results_df[['complete']])]



## ----bench-fit-png, fig.dim=c(5,2.5), fig.pos='!htb', fig.cap='Time required to evaluate the likelihood function for example data sets with a range of sample sizes ($n_o$). Cases where the observed data form a complete regular grid are indicated by dashed lines, whereas incomplete cases are indicated with solid lines. The likelihood function in snapKrig optimized for low memory use and fast computation in the complete case.', fig.alt='A line chart shows several different coloured lines (representing different packages) increasing at an exponential rate. Each one roughly follows the same trajectory except the blue dotted line (snapKrig, with complete data), which has a much shallower growth rate.'----

# plot time to fit the model against number of observed points
ggplot(subset(results_df, pkg != 'gstat')) +
  aes(x=n_in, y=teval_lik, color=pkg, lty=is_complete) +
  geom_point(size=1, pch=1) +
  geom_line(lwd=0.5) +
  scale_linetype_manual(values=c(no='solid', yes='11')) +
  xlab('number of observed points') +
  ylab('likelihood function evaluation time (seconds)') +
  labs(color='R package',
       lty='complete grid') +
  scale_x_log10(
    breaks = scales::trans_breaks('log10', function(x) 10^x),
    labels = scales::trans_format('log10', scales::math_format(10^.x))
  ) +
  scale_y_log10(
    breaks = scales::trans_breaks('log10', function(x) 10^x),
    labels = scales::trans_format('log10', scales::math_format(10^.x))
  ) +
  theme_bw() +
  theme(text=element_text(size=8),
        strip.text.x=element_text(face='bold'),
        strip.text.y=element_text(face='bold'))


## ----bench-pred-png, fig.dim=c(6,4), fig.pos='[!tb]', escape=FALSE, fig.cap='A comparison of computational performance in kriging as a function of the number of points predicted, $n_p$. Dashed lines indicate prediction time on its own, and solid lines indicate time to compute both predictions and variance. Panels separate results from six examples. Prediction with snapKrig is much faster on large-$n_p$ problems than the tested alternatives. This improvement grows with number of observed points $n_o$, and is most pronounced on complete grid problems (bottom row).', fig.alt='A set of six panels are shown, one for each of the (differently sized) datasets. In each panel a set of coloured lines run from the lower left to the upper right, showing computation time increasing with prediction set size.'----
# names of the two groups of example datasets (pts = incomplete, rast = complete)
pts_names = c('ozone', 'meuse', 'treed')
rast_names = paste0('treed_', c(88, 352, 1376))

# reorder data to reflect the panel order we want in the plot
results_plot_df = results_df[ results_df[['name']] %in% c(pts_names, rast_names),]
results_plot_df = results_plot_df[order( match(results_plot_df[['name']], c(pts_names, rast_names)) ),]

# create titles with sample size and order by input size
results_plot_df[['n_plot']] = paste0('(n_o=', results_plot_df[['n_in']], ')')
results_plot_df[['name_plot']] = apply(results_plot_df[, c('name', 'n_plot')], 1, paste, collapse=' ')
results_plot_df[['name_plot']] = factor(results_plot_df[['name_plot']], levels=unique(results_plot_df[['name_plot']]))

# make a plotting data frame with single column for both times
n_case = nrow(results_plot_df)
results_plot_df = results_plot_df[rep(seq(n_case), 2),]
results_plot_df[['with_var']] = rep(c('yes', 'no'), each=n_case)
results_plot_df[['teval']] = results_plot_df[['teval_pred']]
results_plot_df[['teval']][seq(n_case)] = results_plot_df[['teval_both']][seq(n_case)]

# make the plot
ggplot(results_plot_df) +
  aes(x=n_out, y=teval, color=pkg, lty=with_var) +
  geom_point(size=1, pch=1) +
  geom_line(lwd=0.5) +
  scale_linetype_manual(values = c(no='11', yes='solid')) +
  xlab('number of points predicted') + 
  ylab('prediction time (seconds)') +
  labs(color='R package',
       lty='with variance') +
  scale_x_log10(
   breaks = scales::trans_breaks('log10', function(x) 10^x),
   labels = scales::trans_format('log10', scales::math_format(10^.x))
  ) +
  scale_y_log10(
   breaks = scales::trans_breaks('log10', function(x) 10^x),
   labels = scales::trans_format('log10', scales::math_format(10^.x))
  ) +
  facet_wrap(vars(name_plot)) +
  #scale_color_viridis(discrete=TRUE, option='turbo') +
  theme_bw() +
  theme(text=element_text(size=8),
        strip.text.x=element_text(face='bold'),
        strip.text.y=element_text(face='bold'))


